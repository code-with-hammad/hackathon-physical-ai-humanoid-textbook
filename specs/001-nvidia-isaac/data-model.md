# Data Model for Module 3: The AI-Robot Brain (NVIDIA Isaac)

This document outlines the key entities and their conceptual relationships within the "AI-Robot Brain (NVIDIA Isaac)" module, focusing on data flow between simulation, perception, and navigation components.

## Entities

### 1. Isaac Sim Environment

- **Description**: The core simulation platform where robot models and environments are defined and simulated.
- **Key Attributes**:
  - `environment_definition`: USD (Universal Scene Description) file describing the scene, assets, and physics.
  - `robot_model`: Reference to the `Humanoid Robot Model` entity.
  - `sensor_configurations`: Definitions for virtual sensors (e.g., cameras, LiDAR, IMU) within the simulation.
  - `synthetic_data_output`: Streams of raw or processed sensor data generated by Isaac Sim.
- **Relationships**: Produces `Synthetic Data` for `Isaac ROS` and `Nav2`.

### 2. Humanoid Robot Model

- **Description**: The bipedal robot model used within Isaac Sim for simulation and navigation.
- **Key Attributes**:
  - `urdf/usd_asset`: The robot's kinematic and dynamic description.
  - `joint_states`: Current angles and velocities of robot joints.
  - `pose`: Position and orientation of the robot in the simulation.
- **Relationships**: Resides within `Isaac Sim Environment`. Controlled by `Nav2`.

### 3. Synthetic Data

- **Description**: Sensor data (e.g., camera images, depth maps, LiDAR point clouds, IMU readings) generated by Isaac Sim.
- **Key Attributes**:
  - `data_type`: (e.g., `sensor_msgs/Image`, `sensor_msgs/PointCloud2`, `sensor_msgs/Imu`).
  - `timestamp`: Time of data generation.
  - `frame_id`: Coordinate frame of the sensor.
  - `data_payload`: Raw sensor readings.
- **Relationships**: Input to `Isaac ROS` and `Nav2`.

### 4. Isaac ROS (Visual SLAM)

- **Description**: ROS 2 packages optimized for NVIDIA GPUs, specifically used here for Visual SLAM.
- **Key Attributes**:
  - `input_data`: `Synthetic Data` from Isaac Sim (e.g., camera images, IMU).
  - `output_map`: Representation of the environment (e.g., point cloud map, occupancy grid).
  - `output_pose_estimate`: Estimated position and orientation of the robot.
- **Relationships**: Consumes `Synthetic Data`. Produces map and pose estimates for `Nav2`.

### 5. Nav2 (ROS 2 Navigation Stack)

- **Description**: Framework for autonomous navigation, configured for humanoid path planning.
- **Key Attributes**:
  - `input_map`: Map of the environment from `Isaac ROS`.
  - `input_pose_estimate`: Current robot pose from `Isaac ROS`.
  - `navigation_goal`: Desired target pose for the robot.
  - `planned_path`: Sequence of poses for the robot to follow.
  - `cmd_vel`: Control commands (e.g., linear/angular velocities) for the `Humanoid Robot Model`.
- **Relationships**: Consumes map and pose estimates from `Isaac ROS`. Controls `Humanoid Robot Model`.

### 6. Visual SLAM

- **Description**: The process of simultaneously estimating the robot's pose and building a map of its environment using visual sensor data.
- **Key Attributes**: (Covered under `Isaac ROS` attributes)
- **Relationships**: Implemented by `Isaac ROS`.

### 7. Path Planning

- **Description**: The process of finding a valid, collision-free trajectory for the robot from a start to a goal location.
- **Key Attributes**: (Covered under `Nav2` attributes)
- **Relationships**: Implemented by `Nav2`.

## Data Flow

`Isaac Sim Environment` --> `Synthetic Data` --> `Isaac ROS (Visual SLAM)` --> (`output_map`, `output_pose_estimate`) --> `Nav2` --> `cmd_vel` --> `Humanoid Robot Model` (within Isaac Sim).

## Validation Rules

- **Synthetic Data**: Must be consistent with simulated physics and sensor models.
- **VSLAM Map**: Must be topologically consistent and accurate within specified error bounds.
- **Nav2 Path**: Must be collision-free and kinematically feasible for the `Humanoid Robot Model`.
